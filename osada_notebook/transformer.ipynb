{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lino/Desktop/Predict-Future-Sales',\n",
       " '/Users/lino/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles',\n",
       " '/Users/lino/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/lib/python',\n",
       " '/Users/lino/opt/anaconda3/envs/datascience/lib/python39.zip',\n",
       " '/Users/lino/opt/anaconda3/envs/datascience/lib/python3.9',\n",
       " '/Users/lino/opt/anaconda3/envs/datascience/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/lino/opt/anaconda3/envs/datascience/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# Over Ride Parent Path.\n",
    "parent_dir_name = 'Predict-Future-Sales'\n",
    "sys_path = ''\n",
    "for p in str(sys.path[0]).split('/'):\n",
    "    if p != parent_dir_name:\n",
    "        sys_path = sys_path + p + '/'\n",
    "    else:\n",
    "        sys_path += parent_dir_name\n",
    "        break\n",
    "\n",
    "sys.path[0] = sys_path\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lino/opt/anaconda3/envs/datascience/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Optional, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import LayerNorm\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "\n",
    "# Mymodule\n",
    "from module.lino import mode_of_freq, making_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "data = mode_of_freq(data)\n",
    "\n",
    "pack = making_dataset(data.iloc[:, -1], span=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer model.\n",
    "\n",
    "    Args:\n",
    "        d_model: encoder/decoder inputsの特徴量数\n",
    "        nhead: Multi-head Attentionのヘッド数\n",
    "        nhid: feedforward neural networkの次元数\n",
    "        nlayers: encoder内のsub-encoder-layerの数\n",
    "        dropout: ドロップアウト率\n",
    "        activation: 活性化関数\n",
    "        use_src_mask: encoderで時系列マスクを適用するか\n",
    "        cat_embs: 各カテゴリ変数におけるカテゴリ数とembedding次元数\n",
    "        fc_dims: decoder outputsに対するfeedforward neural networkの次元数\n",
    "        device: cpu or gpu\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        nhead: int = 8,\n",
    "        nhid: int = 2048,\n",
    "        nlayers: int = 6,\n",
    "        dropout: float = 0.1,\n",
    "        activation: str = \"relu\",\n",
    "        use_src_mask: bool = False,\n",
    "        fc_dims: Optional[List[int]] = None,\n",
    "        device: Optional[bool] = None,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # デバイスの選定\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        # アトリビュートの格納先\n",
    "        self.tgt_mask = None\n",
    "        self.src_mask = None\n",
    "        self.use_src_mask = use_src_mask\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model, nhead, nhid, dropout, activation\n",
    "        )\n",
    "        encoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_encoder = TransformerEncoder(\n",
    "            encoder_layers, nlayers, encoder_norm\n",
    "        )\n",
    "\n",
    "        decoder_layers = TransformerDecoderLayer(\n",
    "            d_model, nhead, nhid, dropout, activation\n",
    "        )\n",
    "        decoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_decoder = TransformerDecoder(\n",
    "            decoder_layers, nlayers, decoder_norm\n",
    "        )\n",
    "\n",
    "        if fc_dims is None:\n",
    "            fc_dims = []\n",
    "\n",
    "        if len(fc_dims) > 0:\n",
    "            fc_layers = []\n",
    "            for i, hdim in enumerate(fc_dims):\n",
    "                if i != 0:\n",
    "                    fc_layers.append(nn.Linear(fc_dims[i - 1], hdim))\n",
    "                    fc_layers.append(nn.Dropout(dropout))\n",
    "                else:\n",
    "                    fc_layers.append(nn.Linear(d_model, hdim))\n",
    "                    fc_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            self.fc = nn.Sequential(*fc_layers)\n",
    "            self.output = nn.Linear(fc_dims[-1], 1)\n",
    "        else:\n",
    "            self.fc = None\n",
    "            self.output = nn.Linear(d_model, 1)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"未来の情報を考慮しないためのマスクを生成.\"\"\"\n",
    "\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"パラメータを初期化.\"\"\"\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Optional[Tensor] = None,\n",
    "        src_cat_idx: Optional[Tensor] = None,\n",
    "        tgt: Optional[Tensor] = None,\n",
    "        tgt_cat_idx: Optional[Tensor] = None,\n",
    "        memory: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Transformerを適用.\n",
    "\n",
    "        Args:\n",
    "            src: Encoder input（数値）\n",
    "            src_cat_idx: Encoder input（カテゴリ）\n",
    "            tgt: Decoder input（数値）\n",
    "            tgt_cat_idx: Decoder input（カテゴリ）\n",
    "            memory: Encoder output\n",
    "        \"\"\"\n",
    "\n",
    "        if src is not None:\n",
    "            src = Variable(src, requires_grad=True).to(self.device).float()\n",
    "\n",
    "            if src_cat_idx is not None:\n",
    "                src_cat = torch.cat(\n",
    "                    [\n",
    "                        emb_layer(src_cat_idx[:, :, cat_i])\n",
    "                        for cat_i, emb_layer in enumerate(self.cat_embs)\n",
    "                    ],\n",
    "                    dim=-1,\n",
    "                )\n",
    "                src = torch.cat([src_cat.to(self.device), src], dim=-1)\n",
    "\n",
    "            src = self.pos_encoder(src)\n",
    "\n",
    "            if self.use_src_mask:\n",
    "                if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                    mask = self._generate_square_subsequent_mask(len(src)).to(\n",
    "                        self.device\n",
    "                    )\n",
    "                    self.src_mask = mask\n",
    "\n",
    "            memory = self.transformer_encoder(src, mask=self.src_mask)\n",
    "\n",
    "        if tgt is None:\n",
    "            return memory\n",
    "        else:\n",
    "            tgt = Variable(tgt, requires_grad=True).to(self.device).float()\n",
    "\n",
    "            if tgt_cat_idx is not None:\n",
    "                tgt_cat = torch.cat(\n",
    "                    [\n",
    "                        emb_layer(tgt_cat_idx[:, :, cat_i])\n",
    "                        for cat_i, emb_layer in enumerate(self.cat_embs)\n",
    "                    ],\n",
    "                    dim=-1,\n",
    "                )\n",
    "                tgt = torch.cat([tgt_cat.to(self.device), tgt], dim=-1)\n",
    "\n",
    "            tgt = self.pos_encoder(tgt)\n",
    "\n",
    "            if self.tgt_mask is None or self.tgt_mask.size(0) != len(tgt):\n",
    "                mask = self._generate_square_subsequent_mask(len(tgt)).to(self.device)\n",
    "                self.tgt_mask = mask\n",
    "\n",
    "            decoder_output = self.transformer_decoder(\n",
    "                tgt, memory, tgt_mask=self.tgt_mask\n",
    "            )\n",
    "\n",
    "            fc_input = decoder_output\n",
    "\n",
    "            if self.fc is not None:\n",
    "                fc_output = self.fc(fc_input)\n",
    "            else:\n",
    "                fc_output = fc_input\n",
    "\n",
    "            output = self.output(fc_output)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional Encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"PositionalEncodingを適用.\"\"\"\n",
    "\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 32])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 32\n",
    "test_x = torch.randn(4, d_model)\n",
    "pos = PositionalEncoding(d_model)\n",
    "pos(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerModel(d_model)\n",
    "out_put = transformer(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "596b88989fc0dc1fed1e4e461c9c9f08188a37ef0bdca6efc263739311be1bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
