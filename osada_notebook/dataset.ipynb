{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_freq(data: pd.DataFrame,\n",
    "                 key='date',\n",
    "                 freq='D',\n",
    "                 mode='sum'\n",
    "                 ) -> pd.DataFrame:\n",
    "    \"\"\"データを基本統計量で統合する\n",
    "    引数:\n",
    "        data: 対象を含むオリジナルデータ\n",
    "        key: 時間軸のカラム名\n",
    "        freq: グループ単位（D: 日ごと, M: 月ごと, Y: 年ごと）\n",
    "        mode: 統計量（sum, mean, etc）\n",
    "    \"\"\"\n",
    "    # 日付をobjectからdate_time型に変更\n",
    "    data[key] = pd.to_datetime(data[key], format=('%d.%m.%Y'))\n",
    "    # 時系列(key)についてグループ単位(freq)の売上数の基本統計量(mode)で出力\n",
    "    mode_of_key = getattr(data.groupby(pd.Grouper(key=key, freq=freq)), mode)\n",
    "    return mode_of_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_and_split(ds: pd.Series, seq: int) -> Tuple[np.ndarray]:\n",
    "    \"\"\"2次元にd_modelずらしたデータと正解データを作成する\n",
    "    引数:\n",
    "        ds: 単変量時系列データ\n",
    "        seq: transformerのシーケンス\n",
    "    \"\"\"\n",
    "    endpoint = len(ds) - (seq + 1)\n",
    "    expanded = np.stack([ds[i: i + seq + 1] for i in range(0, endpoint)])\n",
    "    x = expanded[:, :-1]\n",
    "    y = expanded[:, -1]\n",
    "    return x, y #,expanded  # for debag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding(x: np.ndarray,\n",
    "                            y:np.ndarray,\n",
    "                            d_model=32,\n",
    "                            dilation=1) -> Tuple[np.ndarray]:\n",
    "    \"\"\"Time Delay Embedding\n",
    "    引数:\n",
    "        x: 訓練データ\n",
    "        y: 正解データ\n",
    "        d_model: エンべディング次元数\n",
    "        dilation: エンべディングの膨張率 \n",
    "    \"\"\"\n",
    "    endpoint = x.shape[0] - d_model * dilation\n",
    "    span = d_model * dilation\n",
    "\n",
    "    tded = [x[i: i + span: dilation, :].T for i in range(endpoint)] \n",
    "    y = y[span - dilation:]\n",
    "    return np.array(tded), np.array(y)\n",
    "\n",
    "## for debag\n",
    "# i = 0\n",
    "# print(expanded[i: i + span: dilation, :][-1,   -2:])\n",
    "# print(tded[i][-1, -1], y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_tgt_split(tded: np.ndarray,\n",
    "                   src_seq: int,\n",
    "                   tgt_seq: int) -> Tuple[np.ndarray]:\n",
    "    \"\"\"エンコーダ入力とデコーダ入力への分割\"\"\"\n",
    "    src = tded[:, :src_seq]\n",
    "    tgt = tded[:, -tgt_seq:]\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch_dataset(src: np.ndarray,\n",
    "                     tgt: np.ndarray,\n",
    "                     label: np.ndarray,\n",
    "                     batch_size: int) -> DataLoader:\n",
    "    \"\"\"Pytorch用のデータセットへの変換\n",
    "    引数:\n",
    "        src: エンコーダ入力データ\n",
    "        tgt: デコーダ入力データ\n",
    "        label: 正解データ\n",
    "        batch_size: ミニバッチのバッチサイズ\n",
    "    \"\"\"\n",
    "    label = label.reshape(-1, 1)[:len(src)]\n",
    "    pack = (src, tgt , label)\n",
    "    pack = [torch.from_numpy(i.astype(np.float32)).clone() for i in pack]\n",
    "    dataset = TensorDataset(*pack)\n",
    "    dataset = DataLoader(dataset, batch_size, shuffle=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_dataset(data,\n",
    "                        trg_column = 'item_cnt_day',\n",
    "                        seq=7,\n",
    "                        d_model=32,\n",
    "                        dilation=1,\n",
    "                        src_tgt_seq=(6, 2),\n",
    "                        batch_size=64):\n",
    "    data = getattr(mode_of_freq(data), trg_column)\n",
    "    x, y = expand_and_split(data, seq=7)\n",
    "    tded, label = time_delay_embedding(x, y, d_model=32, dilation=1)\n",
    "    src, tgt = src_tgt_split(tded, *src_tgt_seq)\n",
    "    dataset = to_torch_dataset(src, tgt, label, batch_size=64)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "dataset = time_series_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fcda949f100>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
