{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "parent_dir = 'Predict-Future-Sales'\n",
    "p_sub = sys.path[0]\n",
    "\n",
    "ride = ''\n",
    "for path in p_sub.split('/'):\n",
    "    if path != parent_dir:\n",
    "        ride = ride + path + '/'\n",
    "    else:\n",
    "        ride = ride + path + '/'\n",
    "        break\n",
    "sys.path[0] = ride\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from typing import Tuple, Optional\n",
    "from pandas import DataFrame, Series, DatetimeIndex\n",
    "from numpy import ndarray\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Delay Embedding に対応したデータセットを出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa22aa18af0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 32]), torch.Size([64, 2, 32]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from module.lino_module.preprocess import time_series_dataset\n",
    "\n",
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "\n",
    "kwrgs = {'data': data,\n",
    "         'seq': 7,\n",
    "         'd_model': 32,\n",
    "         'dilation': 1,\n",
    "         'src_tgt_seq': (6, 2),\n",
    "         'batch_size': 64}\n",
    "\n",
    "train, test = time_series_dataset(**kwrgs)\n",
    "print(train)\n",
    "src, tgt, y = next(iter(train))\n",
    "src.shape, tgt.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成した関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_dataset(data: DataFrame,\n",
    "                        seq: int,\n",
    "                        d_model: int,\n",
    "                        dilation: int,\n",
    "                        src_tgt_seq: Tuple[int],\n",
    "                        batch_size: int,\n",
    "                        trg_column='item_cnt_day') -> Tuple[DataLoader]:\n",
    "    \"\"\"TDEデータセットのメイン関数\"\"\"\n",
    "    data = getattr(mode_of_freq(data), trg_column)\n",
    "    data = StandardScaler().fit_transform(data.values.reshape(-1, 1))\n",
    "    data = data.reshape(-1)\n",
    "    x, y = expand_and_split(data, seq)\n",
    "    tded, label = time_delay_embedding(x, y, d_model, dilation)\n",
    "    src, tgt = src_tgt_split(tded, *src_tgt_seq)\n",
    "    train, test = to_torch_dataset(src, tgt, label, batch_size)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_freq(data: DataFrame,\n",
    "                 key='date',\n",
    "                 freq='D',\n",
    "                 mode='sum'\n",
    "                 ) -> DataFrame:\n",
    "    \"\"\"時系列データを基本統計量で統合する\n",
    "    引数:\n",
    "        data: 対象を含むオリジナルデータ\n",
    "        key: 時間軸のカラム名\n",
    "        freq: グループ単位（D: 日ごと, M: 月ごと, Y: 年ごと）\n",
    "        mode: 統計量（sum, mean, etc）\n",
    "    \"\"\"\n",
    "    # 日付をobjectからdate_time型に変更\n",
    "    data[key] = pd.to_datetime(data[key], format=('%d.%m.%Y'))\n",
    "    # 時系列(key)についてグループ単位(freq)の売上数の基本統計量(mode)で出力\n",
    "    mode_of_key = getattr(data.groupby(pd.Grouper(key=key, freq=freq)), mode)\n",
    "    return mode_of_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_and_split(ds: Series, seq: int) -> Tuple[ndarray]:\n",
    "    \"\"\"2次元にd_modelずらしたデータと正解データを作成する\n",
    "    引数:\n",
    "        ds: 単変量時系列データ\n",
    "        seq: transformerのシーケンス\n",
    "    \"\"\"\n",
    "    endpoint = len(ds) - (seq + 1)\n",
    "    expanded = np.stack([ds[i: i + seq + 1] for i in range(0, endpoint)])\n",
    "    x = expanded[:, :-1]\n",
    "    y = expanded[:, -1]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding(x: ndarray,\n",
    "                         y: Optional[ndarray],\n",
    "                         d_model: int,\n",
    "                         dilation: int\n",
    "                         ) -> Tuple[ndarray]:\n",
    "    \"\"\"Time Delay Embedding\n",
    "    引数:\n",
    "        x: 訓練データ\n",
    "        y: 正解データ\n",
    "        d_model: エンべディング次元数\n",
    "        dilation: エンべディングの間隔\n",
    "    \"\"\"\n",
    "    endpoint = x.shape[0] - d_model * (dilation + 1)\n",
    "    span = d_model * (dilation + 1)\n",
    "\n",
    "    tded = [x[i: i + span: (dilation + 1), :].T for i in range(endpoint)]\n",
    "    if y is not None:\n",
    "        y = y[span - (dilation + 1):]\n",
    "        return np.array(tded), np.array(y)\n",
    "    return np.array(tded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_tgt_split(tded: ndarray,\n",
    "                  src_seq: int,\n",
    "                  tgt_seq: int\n",
    "                  ) -> Tuple[ndarray]:\n",
    "    \"\"\"エンコーダ入力とデコーダ入力への分割\"\"\"\n",
    "    src = tded[:, :src_seq]\n",
    "    tgt = tded[:, -tgt_seq:]\n",
    "    return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch_dataset(src: ndarray,\n",
    "                     tgt: ndarray,\n",
    "                     label: ndarray,\n",
    "                     batch_size: int,\n",
    "                     train_rate=0.9\n",
    "                     ) -> DataLoader:\n",
    "    \"\"\"Pytorch用のデータセットへの変換\n",
    "    引数:\n",
    "        src: エンコーダ入力データ\n",
    "        tgt: デコーダ入力データ\n",
    "        label: 正解データ\n",
    "        batch_size: ミニバッチのバッチサイズ\n",
    "    \"\"\"\n",
    "    label = label.reshape(-1, 1)[:len(src)]\n",
    "    pack = (src, tgt, label)\n",
    "    train_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[:int(len(src) * train_rate)]\n",
    "        for i in pack\n",
    "        ]\n",
    "    test_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[int(len(src) * train_rate):]\n",
    "        for i in pack\n",
    "        ]\n",
    "    train = TensorDataset(*train_pack)\n",
    "    train = DataLoader(train, batch_size, shuffle=False)\n",
    "    test = TensorDataset(*test_pack)\n",
    "    test = DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
