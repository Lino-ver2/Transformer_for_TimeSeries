{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lino/opt/anaconda3/envs/for_pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "parent_dir = 'Predict-Future-Sales'\n",
    "p_sub = sys.path[0]\n",
    "\n",
    "ride = ''\n",
    "for path in p_sub.split('/'):\n",
    "    if path != parent_dir:\n",
    "        ride = ride + path + '/'\n",
    "    else:\n",
    "        ride = ride + path + '/'\n",
    "        break\n",
    "sys.path[0] = ride\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DatetimeIndex\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from module.lino_module.preprocess import mode_of_freq, expand_and_split,\\\n",
    "                                          time_delay_embedding, src_tgt_split,\\\n",
    "                                          to_torch_dataset\n",
    "from typing import Tuple, Optional, Union\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, Series\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Delay Embedding に対応させた曜日と月時情報をd_modelにconcatしたデータセットを出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- src ------------------\n",
      "tensor([[ 0.0000,  7.0000, 14.0000, 21.0000,  0.1667,  0.1667,  0.1667,  0.1667,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  8.0000, 15.0000, 22.0000,  0.3333,  0.3333,  0.3333,  0.3333,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.0000,  9.0000, 16.0000, 23.0000,  0.5000,  0.5000,  0.5000,  0.5000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 3.0000, 10.0000, 17.0000, 24.0000,  0.6667,  0.6667,  0.6667,  0.6667,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.0000, 11.0000, 18.0000, 25.0000,  0.8333,  0.8333,  0.8333,  0.8333,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 5.0000, 12.0000, 19.0000, 26.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "----------------- Data -----------------\n",
      "tensor([[ 0.,  7., 14., 21.],\n",
      "        [ 1.,  8., 15., 22.],\n",
      "        [ 2.,  9., 16., 23.],\n",
      "        [ 3., 10., 17., 24.],\n",
      "        [ 4., 11., 18., 25.],\n",
      "        [ 5., 12., 19., 26.]])\n",
      "---------------- weekly ----------------\n",
      "tensor([[0.1667, 0.1667, 0.1667, 0.1667],\n",
      "        [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "        [0.5000, 0.5000, 0.5000, 0.5000],\n",
      "        [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "        [0.8333, 0.8333, 0.8333, 0.8333],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "--------------- monthly ----------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from module.lino_module.preprocess import tde_dataset_wm\n",
    "\n",
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "data = mode_of_freq(data).item_cnt_day\n",
    "demo = np.arange(len(data))\n",
    "ds = pd.Series(demo , index=data.index)\n",
    "\n",
    "d_model = 4\n",
    "dilation = 6\n",
    "\n",
    "kwrgs ={'data': ds,\n",
    "        'seq': 7,\n",
    "        'd_model': d_model,\n",
    "        'dilation': dilation,\n",
    "        'src_tgt_seq': (6, 2),\n",
    "        'batch_size': 64,\n",
    "        'scaler': None,\n",
    "        'weekly': True,\n",
    "        'monthly': True,\n",
    "        'train_rate': 0.9\n",
    "        }\n",
    "\n",
    "train, test = tde_dataset_wm(**kwrgs)\n",
    "src, tgt, y = next(iter(train))\n",
    "\n",
    "center = 40\n",
    "print(' src '.center(center, '-'))\n",
    "print(src[0])\n",
    "print(' Data '.center(center, '-'))\n",
    "print(src[0][:, :d_model])\n",
    "print(' weekly '.center(center, '-'))\n",
    "print(src[0][:, d_model:d_model*2])\n",
    "print(' monthly '.center(center, '-'))\n",
    "print(src[0][:, d_model*2:d_model*3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下はデータセット用に作成した関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tde_dataset_wm(data: Series,\n",
    "                   seq: int,\n",
    "                   d_model: int,\n",
    "                   dilation: int,\n",
    "                   src_tgt_seq: Tuple[int],\n",
    "                   batch_size: int,\n",
    "                   scaler: Optional[Union[StandardScaler, MinMaxScaler]],\n",
    "                   weekly=True,\n",
    "                   monthly=True,\n",
    "                   train_rate=0.9\n",
    "                   ) -> Tuple[DataLoader]:\n",
    "    \"\"\"TDEに対応した曜日ラベルと月ラベル付与したデータセットのメイン関数\"\"\"\n",
    "    index = data.index\n",
    "    if scaler is not None:\n",
    "        data = scaler().fit_transform(data.values.reshape(-1, 1))\n",
    "        data = data.reshape(-1)\n",
    "    x, y = expand_and_split(data, seq)\n",
    "    tded, label = delay_embeddings(\n",
    "                                   x, y,\n",
    "                                   index,\n",
    "                                   d_model,\n",
    "                                   dilation,\n",
    "                                   seq,\n",
    "                                   weekly, monthly)\n",
    "    src, tgt = src_tgt_split(tded, *src_tgt_seq)\n",
    "    train, test = to_torch_dataset(src, tgt, label, batch_size, train_rate)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_freq(data: DataFrame,\n",
    "                 key='date',\n",
    "                 freq='D',\n",
    "                 mode='sum'\n",
    "                 ) -> DataFrame:\n",
    "    \"\"\"時系列データを基本統計量で統合する\n",
    "    引数:\n",
    "        data: 対象を含むオリジナルデータ\n",
    "        key: 時間軸のカラム名\n",
    "        freq: グループ単位（D: 日ごと, M: 月ごと, Y: 年ごと）\n",
    "        mode: 統計量（sum, mean, etc）\n",
    "    \"\"\"\n",
    "    # 日付をobjectからdate_time型に変更\n",
    "    data[key] = pd.to_datetime(data[key], format=('%d.%m.%Y'))\n",
    "    # 時系列(key)についてグループ単位(freq)の売上数の基本統計量(mode)で出力\n",
    "    mode_of_key = getattr(data.groupby(pd.Grouper(key=key, freq=freq)), mode)\n",
    "    return mode_of_key()\n",
    "\n",
    "\n",
    "def expand_and_split(ds: Series, seq: int) -> Tuple[ndarray]:\n",
    "    \"\"\"2次元にd_modelずらしたデータと正解データを作成する\n",
    "    引数:\n",
    "        ds: 単変量時系列データ\n",
    "        seq: transformerのシーケンス\n",
    "    \"\"\"\n",
    "    endpoint = len(ds) - (seq + 1)\n",
    "    expanded = np.stack([ds[i: i + seq + 1] for i in range(0, endpoint)])\n",
    "    x = expanded[:, :-1]\n",
    "    y = expanded[:, -1]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def time_delay_embedding(x: ndarray,\n",
    "                         y: Optional[ndarray],\n",
    "                         d_model: int,\n",
    "                         dilation: int\n",
    "                         ) -> Tuple[ndarray]:\n",
    "    \"\"\"Time Delay Embedding\n",
    "    引数:\n",
    "        x: 訓練データ\n",
    "        y: 正解データ\n",
    "        d_model: エンべディング次元数\n",
    "        dilation: エンべディングの間隔\n",
    "    \"\"\"\n",
    "    endpoint = x.shape[0] - d_model * (dilation + 1)\n",
    "    span = d_model * (dilation + 1)\n",
    "\n",
    "    tded = [x[i: i + span: (dilation + 1), :].T for i in range(endpoint)]\n",
    "    if y is not None:\n",
    "        y = y[span - (dilation + 1):]\n",
    "        return np.array(tded), np.array(y)\n",
    "    return np.array(tded)\n",
    "\n",
    "\n",
    "def delay_embeddings(x: ndarray,\n",
    "                     y: ndarray,\n",
    "                     index: DatetimeIndex,\n",
    "                     d_model: int,\n",
    "                     dilation: int,\n",
    "                     seq: int,\n",
    "                     weekly: bool,\n",
    "                     monthly: bool):\n",
    "    \"\"\"TDEに対応した曜日、月時ラベルをconcatする\"\"\"\n",
    "    # Time Delay Embedding\n",
    "    tded, label = time_delay_embedding(x, y, d_model, dilation)\n",
    "\n",
    "    # 曜日ラベル\n",
    "    if weekly:\n",
    "        # positional encodingのために0-1でスケーリング\n",
    "        scaled_weekday = index.weekday / 6\n",
    "        week, _ = expand_and_split(scaled_weekday, seq)\n",
    "        tded_week = time_delay_embedding(week, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_week), axis=2)\n",
    "\n",
    "    # 月ラベル\n",
    "    if monthly:\n",
    "        # positional encodingのために0-1でスケーリング\n",
    "        scaled_month = (index.month - 1) / 11\n",
    "        month, _ = expand_and_split(scaled_month, seq)\n",
    "        tded_month = time_delay_embedding(month, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_month), axis=2)\n",
    "    return tded, label\n",
    "\n",
    "\n",
    "def src_tgt_split(tded: ndarray,\n",
    "                  src_seq: int,\n",
    "                  tgt_seq: int\n",
    "                  ) -> Tuple[ndarray]:\n",
    "    \"\"\"エンコーダ入力とデコーダ入力への分割\"\"\"\n",
    "    # 推論時\n",
    "    if tded.ndim == 2:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src.T, tgt.T\n",
    "    # 訓練時（バッチ対応）\n",
    "    if tded.ndim == 3:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src, tgt\n",
    "\n",
    "\n",
    "def to_torch_dataset(src: ndarray,\n",
    "                     tgt: ndarray,\n",
    "                     label: ndarray,\n",
    "                     batch_size: int,\n",
    "                     train_rate: float\n",
    "                     ) -> DataLoader:\n",
    "    \"\"\"Pytorch用のデータセットへの変換\n",
    "    引数:\n",
    "        src: エンコーダ入力データ\n",
    "        tgt: デコーダ入力データ\n",
    "        label: 正解データ\n",
    "        batch_size: ミニバッチのバッチサイズ\n",
    "    \"\"\"\n",
    "    label = label.reshape(-1, 1)[:len(src)]\n",
    "    pack = (src, tgt, label)\n",
    "    train_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[: int(len(src) * train_rate)]\n",
    "        for i in pack\n",
    "        ]\n",
    "    test_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[int(len(src) * train_rate):]\n",
    "        for i in pack\n",
    "        ]\n",
    "    train = TensorDataset(*train_pack)\n",
    "    train = DataLoader(train, batch_size, shuffle=False)\n",
    "    test = TensorDataset(*test_pack)\n",
    "    test = DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train, test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
