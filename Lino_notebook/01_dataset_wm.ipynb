{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lino/opt/anaconda3/envs/for_pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "parent_dir = 'Predict-Future-Sales'\n",
    "p_sub = sys.path[0]\n",
    "\n",
    "ride = ''\n",
    "for path in p_sub.split('/'):\n",
    "    if path != parent_dir:\n",
    "        ride = ride + path + '/'\n",
    "    else:\n",
    "        ride = ride + path + '/'\n",
    "        break\n",
    "sys.path[0] = ride\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from typing import Tuple, Optional, Union\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, Series, DatetimeIndex\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Delay Embedding に対応させた曜日と月時情報をd_modelにconcatしたデータセットを出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- src_data ---------------\n",
      "tensor([[ 0.,  7., 14., 21.],\n",
      "        [ 1.,  8., 15., 22.],\n",
      "        [ 2.,  9., 16., 23.],\n",
      "        [ 3., 10., 17., 24.],\n",
      "        [ 4., 11., 18., 25.],\n",
      "        [ 5., 12., 19., 26.]])\n",
      "---------------- daily -----------------\n",
      "tensor([[0.0323, 0.2581, 0.4839, 0.7097],\n",
      "        [0.0645, 0.2903, 0.5161, 0.7419],\n",
      "        [0.0968, 0.3226, 0.5484, 0.7742],\n",
      "        [0.1290, 0.3548, 0.5806, 0.8065],\n",
      "        [0.1613, 0.3871, 0.6129, 0.8387],\n",
      "        [0.1935, 0.4194, 0.6452, 0.8710]])\n",
      "---------------- weekly ----------------\n",
      "tensor([[0.1667, 0.1667, 0.1667, 0.1667],\n",
      "        [0.3333, 0.3333, 0.3333, 0.3333],\n",
      "        [0.5000, 0.5000, 0.5000, 0.5000],\n",
      "        [0.6667, 0.6667, 0.6667, 0.6667],\n",
      "        [0.8333, 0.8333, 0.8333, 0.8333],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000]])\n",
      "-------------- weekly_num --------------\n",
      "tensor([[0.0000, 0.0227, 0.0455, 0.0682],\n",
      "        [0.0000, 0.0227, 0.0455, 0.0682],\n",
      "        [0.0000, 0.0227, 0.0455, 0.0682],\n",
      "        [0.0000, 0.0227, 0.0455, 0.0682],\n",
      "        [0.0000, 0.0227, 0.0455, 0.0682],\n",
      "        [0.0000, 0.0227, 0.0455, 0.0682]])\n",
      "--------------- monthly ----------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "------------------ y -------------------\n",
      "tensor([26., 27., 28.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 20]), torch.Size([64, 3, 20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from module.lino_module.preprocess import tde_dataset_wm, mode_of_freq\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "data = mode_of_freq(data).item_cnt_day\n",
    "demo = np.arange(len(data))\n",
    "ds = pd.Series(demo , index=data.index)\n",
    "\n",
    "d_model = 4\n",
    "dilation = 6\n",
    "\n",
    "kwrgs ={'data': ds,\n",
    "        'seq': 7,\n",
    "        'd_model': d_model,\n",
    "        'dilation': dilation,\n",
    "        'src_tgt_seq': (6, 3),\n",
    "        'step_num': 2,\n",
    "        'batch_size': 64,\n",
    "        'scaler': None,\n",
    "        'daily': True,\n",
    "        'weekly': True,\n",
    "        'weekly_num': True,\n",
    "        'monthly': True,\n",
    "        'train_rate': 0.9\n",
    "        }\n",
    "\n",
    "train, test = tde_dataset_wm(**kwrgs)\n",
    "src, tgt, y = next(iter(train))\n",
    "\n",
    "center = 40\n",
    "print(' src_data '.center(center, '-'))\n",
    "print(src[0][:, :d_model])\n",
    "print(' daily '.center(center, '-'))\n",
    "print(src[0][:, d_model:d_model*2])\n",
    "print(' weekly '.center(center, '-'))\n",
    "print(src[0][:, d_model*2:d_model*3])\n",
    "print(' weekly_num '.center(center, '-'))\n",
    "print(src[0][:, d_model*3:d_model*4])\n",
    "print(' monthly '.center(center, '-'))\n",
    "print(src[0][:, d_model*4:d_model*5])\n",
    "print(' y '.center(center, '-'))\n",
    "print(y[0])\n",
    "src.shape, tgt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下はデータセット用に作成した関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_freq(data: DataFrame,\n",
    "                 key='date',\n",
    "                 freq='D',\n",
    "                 mode='sum'\n",
    "                 ) -> DataFrame:\n",
    "    \"\"\"時系列データを基本統計量で統合する\n",
    "    引数:\n",
    "        data: 対象を含むオリジナルデータ\n",
    "        key: 時間軸のカラム名\n",
    "        freq: グループ単位（D: 日ごと, M: 月ごと, Y: 年ごと）\n",
    "        mode: 統計量（sum, mean, etc）\n",
    "    \"\"\"\n",
    "    # 日付をobjectからdate_time型に変更\n",
    "    data[key] = pd.to_datetime(data[key], format=('%d.%m.%Y'))\n",
    "    # 時系列(key)についてグループ単位(freq)の売上数の基本統計量(mode)で出力\n",
    "    mode_of_key = getattr(data.groupby(pd.Grouper(key=key, freq=freq)), mode)\n",
    "    return mode_of_key()\n",
    "\n",
    "\n",
    "def tde_dataset_wm(data: Series,\n",
    "                   seq: int,\n",
    "                   d_model: int,\n",
    "                   dilation: int,\n",
    "                   src_tgt_seq: Tuple[int],\n",
    "                   step_num: int,\n",
    "                   batch_size: int,\n",
    "                   scaler: Optional[Union[StandardScaler, MinMaxScaler]],\n",
    "                   daily: bool,\n",
    "                   weekly: bool,\n",
    "                   weekly_num: bool,\n",
    "                   monthly: bool,\n",
    "                   train_rate: float,\n",
    "                   ) -> Tuple[DataLoader]:\n",
    "    \"\"\"TDEに対応した曜日ラベルと月ラベル付与したデータセットのメイン関数\"\"\"\n",
    "    df = data.copy()\n",
    "    if scaler is not None:\n",
    "        data_index = data.index\n",
    "        values = scaler().fit_transform(data.values.reshape(-1, 1))\n",
    "        df[data_index] = values.reshape(-1)\n",
    "    tded, label = delay_embeddings(df,\n",
    "                                   d_model,\n",
    "                                   dilation,\n",
    "                                   seq,\n",
    "                                   src_tgt_seq,\n",
    "                                   step_num,\n",
    "                                   daily, weekly, weekly_num, monthly)\n",
    "    src, tgt = src_tgt_split(tded, *src_tgt_seq)\n",
    "    train, test = to_torch_dataset(src, tgt, label, batch_size, train_rate)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def delay_embeddings(data: Series,\n",
    "                     d_model: int,\n",
    "                     dilation: int,\n",
    "                     seq: int,\n",
    "                     src_tgt_seq: Tuple[int],\n",
    "                     step_num: int,\n",
    "                     daily: bool,\n",
    "                     weekly: bool,\n",
    "                     weekly_num: bool,\n",
    "                     monthly: bool):\n",
    "    \"\"\"TDEに対応した曜日、月時ラベルをconcatする\"\"\"\n",
    "    # Time Delay Embedding\n",
    "    index = data.index\n",
    "    x, y = expand_and_split(data, seq, src_tgt_seq[1], step_num)\n",
    "    tded, label = time_delay_embedding(x, y, d_model, dilation)\n",
    "\n",
    "    # デイリーラベル\n",
    "    if daily:\n",
    "        scaled_day = index.day / 31  # 0-1正規化\n",
    "        day, _ = expand_and_split(scaled_day, seq, src_tgt_seq[1], step_num)\n",
    "        tded_day = time_delay_embedding(day, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_day), axis=2)\n",
    "\n",
    "    # 曜日ラベル\n",
    "    if weekly:\n",
    "        scaled_weekday = index.weekday / 6  # 0-1正規化\n",
    "        week, _ = expand_and_split(scaled_weekday, seq, src_tgt_seq[1], step_num)\n",
    "        tded_week = time_delay_embedding(week, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_week), axis=2)\n",
    "\n",
    "    # 週次ラベル\n",
    "    if weekly_num:\n",
    "        scaled_week_num = (index.isocalendar().week - 1) / 44  # 0-1正規化\n",
    "        week_num, _ = expand_and_split(scaled_week_num, seq, src_tgt_seq[1], step_num)\n",
    "        tded_week_num = time_delay_embedding(week_num, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_week_num), axis=2)\n",
    "\n",
    "    # 月ラベル\n",
    "    if monthly:\n",
    "        scaled_month = (index.month - 1) / 11  # 0-1正規化\n",
    "        month, _ = expand_and_split(scaled_month, seq, src_tgt_seq[1], step_num)\n",
    "        tded_month = time_delay_embedding(month, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_month), axis=2)\n",
    "    return tded, label\n",
    "\n",
    "\n",
    "def expand_and_split(ds: Series,\n",
    "                     seq: int,\n",
    "                     tgt_seq: int,\n",
    "                     step_num: int\n",
    "                     ) -> Tuple[ndarray]:\n",
    "    \"\"\"2次元にd_modelずらしたデータと正解データを作成する\n",
    "    引数:\n",
    "        ds: 単変量時系列データ\n",
    "        seq: transformerのシーケンス\n",
    "    \"\"\"\n",
    "    endpoint = len(ds) - (seq + 1)\n",
    "    expanded = np.stack([ds[i: i + seq + 1] for i in range(0, endpoint)])\n",
    "    x = expanded[:, :-step_num]\n",
    "    y = expanded[:, -tgt_seq:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def time_delay_embedding(x: ndarray,\n",
    "                         y: Optional[ndarray],\n",
    "                         d_model: int,\n",
    "                         dilation: int\n",
    "                         ) -> Tuple[ndarray]:\n",
    "    \"\"\"Time Delay Embedding\n",
    "    引数:\n",
    "        x: 訓練データ\n",
    "        y: 正解データ\n",
    "        d_model: エンべディング次元数\n",
    "        dilation: エンべディングの間隔\n",
    "    \"\"\"\n",
    "    endpoint = x.shape[0] - d_model * (dilation + 1)\n",
    "    span = d_model * (dilation + 1)\n",
    "\n",
    "    tded = [x[i: i + span: (dilation + 1), :].T for i in range(endpoint)]\n",
    "    if y is not None:\n",
    "        y = y[span - (dilation + 1):]\n",
    "        return np.array(tded), np.array(y)\n",
    "    return np.array(tded)\n",
    "\n",
    "\n",
    "def src_tgt_split(tded: ndarray,\n",
    "                  src_seq: int,\n",
    "                  tgt_seq: int\n",
    "                  ) -> Tuple[ndarray]:\n",
    "    \"\"\"エンコーダ入力とデコーダ入力への分割\"\"\"\n",
    "    # 推論時\n",
    "    if tded.ndim == 2:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src.T, tgt.T\n",
    "    # 訓練時（バッチ対応）\n",
    "    if tded.ndim == 3:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src, tgt\n",
    "\n",
    "\n",
    "def to_torch_dataset(src: ndarray,\n",
    "                     tgt: ndarray,\n",
    "                     label: ndarray,\n",
    "                     batch_size: int,\n",
    "                     train_rate: float\n",
    "                     ) -> DataLoader:\n",
    "    \"\"\"Pytorch用のデータセットへの変換\n",
    "    引数:\n",
    "        src: エンコーダ入力データ\n",
    "        tgt: デコーダ入力データ\n",
    "        label: 正解データ\n",
    "        batch_size: ミニバッチのバッチサイズ\n",
    "    \"\"\"\n",
    "    if label.ndim == 1:\n",
    "        label = label.reshape(-1, 1)[:len(src)]\n",
    "    if label.ndim == 2:\n",
    "        label = label[:len(src)]\n",
    "    pack = (src, tgt, label)\n",
    "    train_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[: int(len(src) * train_rate)]\n",
    "        for i in pack\n",
    "        ]\n",
    "    test_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[int(len(src) * train_rate):]\n",
    "        for i in pack\n",
    "        ]\n",
    "    train = TensorDataset(*train_pack)\n",
    "    train = DataLoader(train, batch_size, shuffle=False)\n",
    "    test = TensorDataset(*test_pack)\n",
    "    test = DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
