{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "parent_dir = 'Predict-Future-Sales'\n",
    "p_sub = sys.path[0]\n",
    "\n",
    "ride = ''\n",
    "for path in p_sub.split('/'):\n",
    "    if path != parent_dir:\n",
    "        ride = ride + path + '/'\n",
    "    else:\n",
    "        ride = ride + path + '/'\n",
    "        break\n",
    "sys.path[0] = ride\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from module.lino_module.preprocess import mode_of_freq\n",
    "\n",
    "from typing import Tuple, Optional, Union\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, Series, DatetimeIndex\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Delay Embedding に対応させた曜日と月時情報をd_modelにconcatしたデータセットを出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2013-01-01       0\n",
       "2013-01-02       1\n",
       "2013-01-03       2\n",
       "2013-01-04       3\n",
       "2013-01-05       4\n",
       "              ... \n",
       "2015-10-27    1029\n",
       "2015-10-28    1030\n",
       "2015-10-29    1031\n",
       "2015-10-30    1032\n",
       "2015-10-31    1033\n",
       "Freq: D, Length: 1034, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from module.lino_module.preprocess import tde_dataset_wm\n",
    "\n",
    "data = pd.read_csv('../data/sales_train.csv')\n",
    "data = mode_of_freq(data).item_cnt_day\n",
    "demo = np.arange(len(data))\n",
    "ds = pd.Series(demo , index=data.index)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 7, 20]), torch.Size([64, 3, 20]), torch.Size([64, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 4\n",
    "kwrgs ={'data': ds,\n",
    "        'seq': 7,\n",
    "        'd_model': d_model,\n",
    "        'dilation': 1,\n",
    "        'src_tgt_seq': (7, 3),\n",
    "        'step_num': 3,\n",
    "        'batch_size': 64,\n",
    "        'scaler': None,\n",
    "        'daily': True,\n",
    "        'weekday': True,\n",
    "        'weekly': True,\n",
    "        'monthly': True,\n",
    "        'train_rate': 0.9 }\n",
    "\n",
    "train, test = tde_dataset_wm(**kwrgs)\n",
    "src, tgt, y = next(iter(train))\n",
    "src.shape, tgt.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- src_data ---------------\n",
      "tensor([[ 0.,  2.,  4.,  6.],\n",
      "        [ 1.,  3.,  5.,  7.],\n",
      "        [ 2.,  4.,  6.,  8.],\n",
      "        [ 3.,  5.,  7.,  9.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [ 5.,  7.,  9., 11.],\n",
      "        [ 6.,  8., 10., 12.]])\n",
      "---------------- daily -----------------\n",
      "tensor([[0.0323, 0.0968, 0.1613, 0.2258],\n",
      "        [0.0645, 0.1290, 0.1935, 0.2581],\n",
      "        [0.0968, 0.1613, 0.2258, 0.2903],\n",
      "        [0.1290, 0.1935, 0.2581, 0.3226],\n",
      "        [0.1613, 0.2258, 0.2903, 0.3548],\n",
      "        [0.1935, 0.2581, 0.3226, 0.3871],\n",
      "        [0.2258, 0.2903, 0.3548, 0.4194]])\n",
      "--------------- weekday ----------------\n",
      "tensor([[0.1667, 0.5000, 0.8333, 0.0000],\n",
      "        [0.3333, 0.6667, 1.0000, 0.1667],\n",
      "        [0.5000, 0.8333, 0.0000, 0.3333],\n",
      "        [0.6667, 1.0000, 0.1667, 0.5000],\n",
      "        [0.8333, 0.0000, 0.3333, 0.6667],\n",
      "        [1.0000, 0.1667, 0.5000, 0.8333],\n",
      "        [0.0000, 0.3333, 0.6667, 1.0000]])\n",
      "---------------- weekly ----------------\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0227],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0227],\n",
      "        [0.0000, 0.0000, 0.0227, 0.0227],\n",
      "        [0.0000, 0.0000, 0.0227, 0.0227],\n",
      "        [0.0000, 0.0227, 0.0227, 0.0227],\n",
      "        [0.0000, 0.0227, 0.0227, 0.0227],\n",
      "        [0.0227, 0.0227, 0.0227, 0.0227]])\n",
      "--------------- monthly ----------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "center = 40\n",
    "print(' src_data '.center(center, '-'))\n",
    "print(src[index][:, :d_model])\n",
    "\n",
    "print(' daily '.center(center, '-'))\n",
    "print(src[index][:, d_model:d_model*2])\n",
    "print(' weekday '.center(center, '-'))\n",
    "print(src[index][:, d_model*2:d_model*3])\n",
    "print(' weekly '.center(center, '-'))\n",
    "print(src[index][:, d_model*3:d_model*4])\n",
    "print(' monthly '.center(center, '-'))\n",
    "print(src[index][:, d_model*4:d_model*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- tgt_data ---------------\n",
      "tensor([[ 4.,  6.,  8., 10.],\n",
      "        [ 5.,  7.,  9., 11.],\n",
      "        [ 6.,  8., 10., 12.]])\n",
      "---------------- daily -----------------\n",
      "tensor([[0.1613, 0.2258, 0.2903, 0.3548],\n",
      "        [0.1935, 0.2581, 0.3226, 0.3871],\n",
      "        [0.2258, 0.2903, 0.3548, 0.4194]])\n",
      "--------------- weekday ----------------\n",
      "tensor([[0.8333, 0.0000, 0.3333, 0.6667],\n",
      "        [1.0000, 0.1667, 0.5000, 0.8333],\n",
      "        [0.0000, 0.3333, 0.6667, 1.0000]])\n",
      "---------------- weekly ----------------\n",
      "tensor([[0.0000, 0.0227, 0.0227, 0.0227],\n",
      "        [0.0000, 0.0227, 0.0227, 0.0227],\n",
      "        [0.0227, 0.0227, 0.0227, 0.0227]])\n",
      "--------------- monthly ----------------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "------------------ y -------------------\n",
      "tensor([13., 14., 15.])\n"
     ]
    }
   ],
   "source": [
    "print(' tgt_data '.center(center, '-'))\n",
    "print(tgt[index][:, :d_model])\n",
    "print(' daily '.center(center, '-'))\n",
    "print(tgt[index][:, d_model:d_model*2])\n",
    "print(' weekday '.center(center, '-'))\n",
    "print(tgt[index][:, d_model*2:d_model*3])\n",
    "print(' weekly '.center(center, '-'))\n",
    "print(tgt[index][:, d_model*3:d_model*4])\n",
    "print(' monthly '.center(center, '-'))\n",
    "print(tgt[index][:, d_model*4:d_model*5])\n",
    "print(' y '.center(center, '-'))\n",
    "print(y[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下はデータセット用に作成した関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_freq(data: DataFrame,\n",
    "                 key='date',\n",
    "                 freq='D',\n",
    "                 mode='sum'\n",
    "                 ) -> DataFrame:\n",
    "    \"\"\"時系列データを基本統計量で統合する\n",
    "    引数:\n",
    "        data: 対象を含むオリジナルデータ\n",
    "        key: 時間軸のカラム名\n",
    "        freq: グループ単位（D: 日ごと, M: 月ごと, Y: 年ごと）\n",
    "        mode: 統計量（sum, mean, etc）\n",
    "    \"\"\"\n",
    "    # 日付をobjectからdate_time型に変更\n",
    "    data[key] = pd.to_datetime(data[key], format=('%d.%m.%Y'))\n",
    "    # 時系列(key)についてグループ単位(freq)の売上数の基本統計量(mode)で出力\n",
    "    mode_of_key = getattr(data.groupby(pd.Grouper(key=key, freq=freq)), mode)\n",
    "    return mode_of_key()\n",
    "\n",
    "\n",
    "def tde_dataset_wm(data: Series,\n",
    "                   seq: int,\n",
    "                   d_model: int,\n",
    "                   dilation: int,\n",
    "                   src_tgt_seq: Tuple[int],\n",
    "                   step_num: int,\n",
    "                   batch_size: int,\n",
    "                   scaler: Optional[Union[StandardScaler, MinMaxScaler]],\n",
    "                   daily: bool,\n",
    "                   weekday: bool,\n",
    "                   weekly:  bool,\n",
    "                   monthly: bool,\n",
    "                   train_rate: float,\n",
    "                   ) -> Tuple[DataLoader]:\n",
    "    \"\"\"TDEに対応した曜日ラベルと月ラベル付与したデータセットのメイン関数\"\"\"\n",
    "    df = data.copy()\n",
    "    if scaler is not None:\n",
    "        data_index = data.index\n",
    "        values = scaler().fit_transform(data.values.reshape(-1, 1))\n",
    "        df[data_index] = values.reshape(-1)\n",
    "    tded, label = delay_embeddings(df,\n",
    "                                   d_model,\n",
    "                                   dilation,\n",
    "                                   seq,\n",
    "                                   src_tgt_seq,\n",
    "                                   step_num,\n",
    "                                   daily, weekday, weekly, monthly)\n",
    "    src, tgt = src_tgt_split(tded, *src_tgt_seq)\n",
    "    train, test = to_torch_dataset(src, tgt, label, batch_size, train_rate)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def delay_embeddings(data: Series, d_model: int, dilation: int, seq: int,\n",
    "                     src_tgt_seq: Tuple[int], step_num: int,\n",
    "                     daily: bool, weekday: bool, weekly: bool, monthly: bool\n",
    "                     ) -> Tuple[ndarray]:\n",
    "    \"\"\"TDEに対応した曜日、月時ラベルをconcatする\"\"\"\n",
    "    # Time Delay Embedding\n",
    "    index = data.index\n",
    "    x, y = expand_and_split(data, seq, src_tgt_seq[1], step_num)\n",
    "    tded, label = time_delay_embedding(x, y, d_model, dilation)\n",
    "\n",
    "    # デイリーラベル\n",
    "    if daily:\n",
    "        scaled_day = index.day / 31  # 0-1正規化\n",
    "        day, _ = expand_and_split(scaled_day, seq, src_tgt_seq[1], step_num)\n",
    "        tded_day = time_delay_embedding(day, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_day), axis=2)\n",
    "\n",
    "    # 曜日ラベル\n",
    "    if weekday:\n",
    "        scaled_weekday = index.weekday / 6  # 0-1正規化\n",
    "        week, _ = expand_and_split(scaled_weekday, seq, src_tgt_seq[1], step_num)\n",
    "        tded_week = time_delay_embedding(week, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_week), axis=2)\n",
    "\n",
    "    # 週次ラベル\n",
    "    if weekly:\n",
    "        scaled_week_num = (index.isocalendar().week - 1) / 44  # 0-1正規化\n",
    "        week_num, _ = expand_and_split(scaled_week_num, seq, src_tgt_seq[1], step_num)\n",
    "        tded_week_num = time_delay_embedding(week_num, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_week_num), axis=2)\n",
    "\n",
    "    # 月ラベル\n",
    "    if monthly:\n",
    "        scaled_month = (index.month - 1) / 11  # 0-1正規化\n",
    "        month, _ = expand_and_split(scaled_month, seq, src_tgt_seq[1], step_num)\n",
    "        tded_month = time_delay_embedding(month, None, d_model, dilation)\n",
    "        tded = np.concatenate((tded, tded_month), axis=2)\n",
    "    return tded, label\n",
    "\n",
    "\n",
    "def expand_and_split(ds: Series,\n",
    "                     seq: int,\n",
    "                     tgt_seq: int,\n",
    "                     step_num: int\n",
    "                     ) -> Tuple[ndarray]:\n",
    "    \"\"\"2次元にd_modelずらしたデータと正解データを作成する\n",
    "    引数:\n",
    "        ds: 単変量時系列データ\n",
    "        seq: transformerのシーケンス\n",
    "    \"\"\"\n",
    "    endpoint = len(ds) - (seq + tgt_seq + 1)\n",
    "    expanded = np.stack([ds[i: i + seq + step_num] for i in range(0, endpoint)])\n",
    "    x = expanded[:, :-step_num]\n",
    "    y = expanded[:, -tgt_seq:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def time_delay_embedding(x: ndarray, y: Optional[ndarray],\n",
    "                         d_model: int, dilation: int) -> Tuple[ndarray]:\n",
    "    \"\"\"Time Delay Embedding\n",
    "    引数:\n",
    "        x: 訓練データ\n",
    "        y: 正解データ\n",
    "        d_model: エンべディング次元数\n",
    "        dilation: エンべディングの間隔\n",
    "    \"\"\"\n",
    "    endpoint = x.shape[0] - d_model * (dilation + 1)\n",
    "    span = d_model * (dilation + 1)\n",
    "\n",
    "    tded = [x[i: i + span: (dilation + 1), :].T for i in range(endpoint)]\n",
    "    if y is not None:\n",
    "        y = y[span - (dilation + 1):]\n",
    "        return np.array(tded), np.array(y)\n",
    "    return np.array(tded)\n",
    "\n",
    "\n",
    "def src_tgt_split(tded: ndarray, src_seq: int, tgt_seq: int) -> Tuple[ndarray]:\n",
    "    \"\"\"エンコーダ入力とデコーダ入力への分割\"\"\"\n",
    "    # 推論時\n",
    "    if tded.ndim == 2:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src.T, tgt.T\n",
    "    # 訓練時（バッチ対応）\n",
    "    if tded.ndim == 3:\n",
    "        src = tded[:, :src_seq]\n",
    "        tgt = tded[:, -tgt_seq:]\n",
    "        return src, tgt\n",
    "\n",
    "\n",
    "def to_torch_dataset(src: ndarray, tgt: ndarray, label: ndarray,\n",
    "                     batch_size: int, train_rate: float) -> DataLoader:\n",
    "    \"\"\"Pytorch用のデータセットへの変換\n",
    "    引数:\n",
    "        src: エンコーダ入力データ\n",
    "        tgt: デコーダ入力データ\n",
    "        label: 正解データ\n",
    "        batch_size: ミニバッチのバッチサイズ\n",
    "    \"\"\"\n",
    "    if label.ndim == 1:\n",
    "        label = label.reshape(-1, 1)[:len(src)]\n",
    "    if label.ndim == 2:\n",
    "        label = label[:len(src)]\n",
    "    pack = (src, tgt, label)\n",
    "    train_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[: int(len(src) * train_rate)]\n",
    "        for i in pack\n",
    "        ]\n",
    "    test_pack = [\n",
    "        torch.from_numpy(i.astype(np.float32))[int(len(src) * train_rate):]\n",
    "        for i in pack\n",
    "        ]\n",
    "    train = TensorDataset(*train_pack)\n",
    "    train = DataLoader(train, batch_size, shuffle=False)\n",
    "    test = TensorDataset(*test_pack)\n",
    "    test = DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
