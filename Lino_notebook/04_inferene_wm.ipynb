{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "parent_dir = 'Predict-Future-Sales'\n",
    "p_sub = sys.path[0]\n",
    "\n",
    "ride = ''\n",
    "for path in p_sub.split('/'):\n",
    "    if path != parent_dir:\n",
    "        ride = ride + path + '/'\n",
    "    else:\n",
    "        ride = ride + path + '/'\n",
    "        break\n",
    "sys.path[0] = ride\n",
    "\n",
    "import pathlib\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from module.lino_module.preprocess import mode_of_freq, src_tgt_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再帰的推論\n",
    "### モデル一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './models/models_wm/'  # Transformer Model\n",
    "# dir_path = './models/models_wm_refit/'  # Transformer Model（Refit）\n",
    "# dir_path = './models/models_ax/'  # Auxiliary Model\n",
    "\n",
    "files = list(pathlib.Path(dir_path).glob('**/*'))\n",
    "for idx, i in enumerate(files):\n",
    "    print(f'Index: {idx}')\n",
    "    print(str(i.name)[:-4])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの呼び出し\n",
    "index = 2\n",
    "model_name = files[index].name[:-4]\n",
    "file_path = dir_path + model_name + '.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    kw = pickle.load(f)\n",
    "\n",
    "# キーワド引数の選定\n",
    "step_num = kw['step_num']\n",
    "\n",
    "# プロットの保存先を設定\n",
    "img_path = './imgs/img_inference/'\n",
    "if dir_path == './models/models_ax/':\n",
    "    img_path = img_path[:-1] + '_ax/'\n",
    "\n",
    "model_type = kw['model']._get_name()\n",
    "print('model type: ', model_type, '\\n model name:', model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定した日数を予測"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最新データから指定日後の予測推移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.lino_module.inference import RecurrentInference\n",
    "\n",
    "# 画像の保存\n",
    "saving = False\n",
    "\n",
    "# 予測日数を設定\n",
    "prediction_days = 360  # 推論日数\n",
    "freq = int(prediction_days / step_num)  # 推論回数\n",
    "ds = kw['data']  # 推論開始データ\n",
    "\n",
    "# 推論\n",
    "self = RecurrentInference(**kw)\n",
    "self(ds)\n",
    "pred = self.predict(freq)\n",
    "title = f'Forecast after {freq * step_num} days'\n",
    "\n",
    "# 描写と保存\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(ds, label='origin', alpha=0.5)\n",
    "plt.plot(pred, label=title)\n",
    "plt.grid(axis='x')\n",
    "plt.title(f'{model_type}\\n'+ model_name)\n",
    "plt.legend()\n",
    "if saving:\n",
    "    plt.savefig(img_path + model_name + f'freq_after_({freq}).png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定日前から最新データ日までの予測推移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測日数の設定\n",
    "prediction_days = 360  # 推論日数\n",
    "freq = int(prediction_days / step_num)  # 推論回数\n",
    "data = ds[:-prediction_days]  # 推論開始データ\n",
    "\n",
    "# 推論\n",
    "self2 = RecurrentInference(**kw)\n",
    "self2(data)\n",
    "from_freq = self2.predict(freq)\n",
    "\n",
    "# 描画と保存\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(ds, label='origin', alpha=0.5, linestyle='dashed')\n",
    "plt.plot(from_freq, label=f'Forecast from {freq * step_num}days ago')\n",
    "plt.grid(axis='x')\n",
    "plt.legend()\n",
    "plt.title(f'{model_type}\\n'+ model_name)\n",
    "if saving:\n",
    "    plt.savefig(img_path + model_name + f'freq_from_({freq}).png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４半期ごとの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# 予測日数の設定\n",
    "span = 90  # データの更新頻度日数\n",
    "prediction_days = 365 + 10 * 30  # 推論日数 月数 日数\n",
    "freq = int(prediction_days / step_num)  # 推論回数\n",
    "\n",
    "# 描画と保存\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(ds, label='origin', alpha=0.5, linestyle='dashed')\n",
    "\n",
    "\n",
    "# 推論\n",
    "cached = prediction_days\n",
    "for _ in range(prediction_days//span + 1):\n",
    "    data = ds[:-cached]  # 推論開始データ\n",
    "    cached -= span\n",
    "    self2 = RecurrentInference(**kw)\n",
    "    self2(data)\n",
    "    from_freq = self2.predict(span//step_num)\n",
    "    plt.plot(from_freq)\n",
    "\n",
    "xmin = datetime.datetime.strptime('2013-01', '%Y-%m')\n",
    "xmax = datetime.datetime.strptime('2016-01', '%Y-%m')\n",
    "plt.xlim([xmin,xmax])\n",
    "\n",
    "locator = mdates.MonthLocator(bymonthday=1, interval=3)\n",
    "plt.gca().xaxis.set_major_locator(locator)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "plt.grid(axis='x')\n",
    "plt.legend()\n",
    "plt.title(f'{model_type}\\n'+ model_name + f'\\nspan: {span}')\n",
    "quarter_path = './imgs/img_quarter/'\n",
    "if saving:\n",
    "    plt.savefig(quarter_path + f'{model_type}' + model_name + f'span_{span}')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下は推論用に作成したクラス"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from module.lino_module.preprocess import src_tgt_split\n",
    "\n",
    "from typing import Tuple, Optional, Union\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, Series, Timestamp\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class RecurrentInference():\n",
    "    \"\"\"再起的に推論を行うクラス\"\"\"\n",
    "    def __init__(self, data, model, seq, d_model, dilation, src_tgt_seq,\n",
    "                 step_num, daily, weekday, weekly, monthly, scaler):\n",
    "        \"\"\" Initializer\n",
    "        引数:\n",
    "            model: 訓練済みモデル\n",
    "            seq: 訓練条件時の seq\n",
    "            d_model: 訓練条件時の d_model\n",
    "            dilation: 訓練条件時の dilation\n",
    "            src_tgt_seq: 訓練条件時の src_tgt_seq,\n",
    "            step_num: 一回の推論における予測日数\n",
    "            daily: 訓練条件時の日付情報の有無\n",
    "            weekday: 訓練条件時の曜日情報の有無\n",
    "            weekly: 訓練条件時の週次情報の有無\n",
    "            monthly: 訓練条件時の月次情報の有無\n",
    "        \"\"\"\n",
    "        self.training_data: Series = data\n",
    "        self.model: object = model\n",
    "        self.seq: int = seq\n",
    "        self.d_model: int = d_model\n",
    "        self.dilation: int = dilation\n",
    "        self.src_tgt_seq: Tuple[int] = src_tgt_seq\n",
    "        self.step_num: int = step_num\n",
    "        self.daily: bool = daily\n",
    "        self.weekday: bool = weekday\n",
    "        self.weekly: bool = weekly\n",
    "        self.monthly: bool = monthly\n",
    "        self.scaler:  Union[StandardScaler, MinMaxScaler] = scaler\n",
    "\n",
    "        self.df: Optional[DataFrame] = None\n",
    "        self.inferenced: Optional[Series] = None\n",
    "        self.embedded: Optional[ndarray] = None\n",
    "        self.latest_index: Optional[Timestamp] = None\n",
    "        self.latest_data: Optional[float] = None\n",
    "\n",
    "    def __call__(self, ds: Series):\n",
    "        \"\"\"入力データを登録\n",
    "        引数:\n",
    "            ds: 訓練データセット作成時に使用したシリーズ\n",
    "            scaler: 訓練時に使用したスケーラー\n",
    "        \"\"\"\n",
    "        fit_target = self.training_data.values.reshape(-1, 1)\n",
    "        self.scaler = self.scaler().fit(fit_target)\n",
    "\n",
    "        reshaped = ds.values.reshape(-1, 1)\n",
    "        scaled_ds = self.scaler.transform(reshaped).reshape(-1)\n",
    "\n",
    "        # 入力データから推論に持ちるデータフレームを生成\n",
    "        self.df = pd.DataFrame(scaled_ds,\n",
    "                               columns=['data'],\n",
    "                               index=ds.index.tolist())\n",
    "        # 推論結果を書くのするデータフレームを生成\n",
    "        self.latest_index = ds.index[-self.step_num:]\n",
    "        self.latest_data = ds[-self.step_num:]\n",
    "        self.inferenced = pd.Series(self.latest_data, index=self.latest_index)\n",
    "\n",
    "        if self.daily:\n",
    "            self.df['daily'] = ds.index.day / 31\n",
    "        if self.weekday:\n",
    "            self.df['weekday'] = ds.index.weekday / 6\n",
    "        if self.weekly:\n",
    "            scaled_calendar = (ds.index.isocalendar().week - 1) / 44\n",
    "            self.df['weekly'] = scaled_calendar.values\n",
    "        if self.monthly:\n",
    "            self.df['monthly'] = (ds.index.month - 1) / 11\n",
    "\n",
    "    def predict(self, freq: int) -> Series:\n",
    "        \"\"\"推論用関数\n",
    "        引数:\n",
    "            freq: 再帰推論回数\n",
    "        \"\"\"\n",
    "        for _ in range(freq):\n",
    "            self.embedded = self.tde(self.df,\n",
    "                                     self.seq,\n",
    "                                     self.d_model,\n",
    "                                     self.dilation)\n",
    "            src, tgt = src_tgt_split(self.embedded, *self.src_tgt_seq)\n",
    "            output = self.inference(self.model, src, tgt).reshape(-1)\n",
    "            scaled = output[-self.step_num:]\n",
    "            inversed = self.scaler.inverse_transform(scaled.reshape(-1, 1))\n",
    "            inversed = inversed.reshape(-1)\n",
    "\n",
    "            # 推論の追加\n",
    "            self.latest_index += datetime.timedelta(self.step_num)\n",
    "            inferenced = pd.Series(inversed, index=self.latest_index)\n",
    "            self.inferenced = pd.concat((self.inferenced, inferenced))\n",
    "\n",
    "            # datasetの更新\n",
    "            latest_data = {'data': scaled}\n",
    "            if self.daily:\n",
    "                scaled_daily = self.latest_index.day / 31\n",
    "                latest_data['daily'] = scaled_daily\n",
    "            if self.weekday:\n",
    "                scaled_weekday = self.latest_index.weekday / 6\n",
    "                latest_data['weekday'] = scaled_weekday\n",
    "            if self.weekly:\n",
    "                scaled_weekly = (self.latest_index.isocalendar().week - 1) / 44\n",
    "                latest_data['weekly'] = scaled_weekly\n",
    "            if self.monthly:\n",
    "                scaled_month = (self.latest_index.month - 1) / 11\n",
    "                latest_data['monthly'] = scaled_month\n",
    "            latest = pd.DataFrame(latest_data, index=self.latest_index)\n",
    "            self.df = pd.concat((self.df, latest))\n",
    "        return self.inferenced[self.step_num:]\n",
    "\n",
    "    @classmethod\n",
    "    def tde(self,\n",
    "            df: DataFrame,\n",
    "            seq: int,\n",
    "            d_model: int,\n",
    "            dilation: int\n",
    "            ) -> ndarray:\n",
    "        \"\"\"Time delay Embedding\n",
    "           入力データ末端のseq分からTDEデータを作成\n",
    "        引数:\n",
    "            df: [data, weekly, monthly]のカラムと Timestamp インデックスを持ったデータフレーム\n",
    "            seq: 訓練条件時の seq\n",
    "            d_model: 訓練条件時の d_model\n",
    "            dilation: 訓練条件時の dilation\n",
    "        \"\"\"\n",
    "        embeded = []\n",
    "        for column in df.columns:\n",
    "            trg = getattr(df, column)\n",
    "            tded = self.tde_for_inference(trg, seq, d_model, dilation)\n",
    "            embeded.append(tded.tolist())\n",
    "        embeded = np.array(embeded).reshape(d_model*len(df.columns), -1)\n",
    "        return embeded\n",
    "\n",
    "    @classmethod\n",
    "    def inference(self, model: object, src: Tensor, tgt: Tensor) -> ndarray:\n",
    "        \"\"\"推論関数\n",
    "        \"\"\"\n",
    "        src = torch.from_numpy(src.astype(np.float32)).unsqueeze(0)\n",
    "        tgt = torch.from_numpy(tgt.astype(np.float32)).unsqueeze(0)\n",
    "        model.eval()\n",
    "        if model._get_name() == 'WithAuxiliary':\n",
    "            base, auxi = model(src, tgt)\n",
    "            output = base.detach().numpy() + auxi.detach().numpy()\n",
    "        else:\n",
    "            output = model(src, tgt).detach().numpy()\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def tde_for_inference(self, ds: Series, seq: int,\n",
    "                          d_model: int, dilation: int) -> ndarray:\n",
    "        for_array = []\n",
    "        for i in range(d_model):\n",
    "            if i != 0:\n",
    "                for_array.append(ds[-seq - i*(dilation + 1): -i*(dilation + 1)])\n",
    "            else:\n",
    "                for_array.append(ds[-seq:])\n",
    "        time_delay_embedded = np.array([j for j in reversed(for_array)])\n",
    "        return time_delay_embedded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f415b4ed372d607fec632355f4d17dd884dbf40d29d4f41bd390ce33285f7d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
